{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling using supervised-learning\n",
    "\n",
    "The end goal is to predict the price per night of a airbnb location depending on several features. \n",
    "\n",
    "We will use the dataset cleaned and preprocessed for modelling (scaling and RFE feature engineering methods). \n",
    "\n",
    "Models to build and compare:\n",
    "- Linear Regression\n",
    "- KNN\n",
    "- RandomForest\n",
    "\n",
    "**Steps:**\n",
    "- Build train/test sample data \n",
    "- Build models\n",
    "- Get evaluation metrics for each models\n",
    "- Compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/airbnb_paris_clean_feat.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "### Models set-up & train/test sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true,y_pred):\n",
    "    if y_true.any() == 0:\n",
    "        return \"dividing by 0 is impossible\"\n",
    "    else:\n",
    "        return np.mean(np.abs((y_true-y_pred)/y_pred))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price', axis=1)\n",
    "y = df.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "model_lin = LinearRegression()\n",
    "model_lin.fit(X_train, y_train)\n",
    "print('R^2 score for X_train:', model_lin.score(X_train, y_train),'\\n')\n",
    "\n",
    "# predicting values\n",
    "y_pred_lin = model_lin.predict(X_test)\n",
    "\n",
    "# checking evaluation metrics\n",
    "print('R^2 score for X_test:',r2_score(y_test,y_pred_lin))\n",
    "print('MSE:', mean_squared_error(y_test,y_pred_lin))\n",
    "print('RMSE:', mean_squared_error(y_test,y_pred_lin, squared=False))\n",
    "print('MAPE:',mape(y_test,y_pred_lin))\n",
    "print('RMSLE:',(mean_squared_log_error(y_test,abs(y_pred_lin))**0.5),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lin[y_pred_lin<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking predictions\n",
    "plt.scatter(y_test,y_pred_lin)\n",
    "plt.title('Prediction Linearity')\n",
    "plt.show()\n",
    "\n",
    "# Checking residuals\n",
    "resid=y_test-y_pred_lin\n",
    "\n",
    "print(resid.mean())\n",
    "plt.plot(resid)\n",
    "plt.title('Residuals Variance')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(resid)\n",
    "plt.title('Distribution of residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model\n",
    "model_knn = KNeighborsRegressor(n_neighbors=3)\n",
    "model_knn.fit(X_train, y_train)\n",
    "print('R^2 score for X_train:', model_knn.score(X_train, y_train),'\\n')\n",
    "\n",
    "# predicting values\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "# checking evaluation metrics\n",
    "print('R^2 score for X_test:', model_knn.score(X_test, y_test))\n",
    "print('MSE:', mean_squared_error(y_test,y_pred_knn))\n",
    "print('RMSE:', mean_squared_error(y_test,y_pred_knn, squared=False))\n",
    "print('MAPE:',mape(y_test,y_pred_knn))\n",
    "print('RMSLE:',(mean_squared_log_error(y_test, y_pred_knn)**0.5),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model\n",
    "model_knn = KNeighborsRegressor(n_neighbors=5)\n",
    "model_knn.fit(X_train, y_train)\n",
    "print('R^2 score for X_train:', model_knn.score(X_train, y_train),'\\n')\n",
    "\n",
    "# predicting values\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "# checking evaluation metrics\n",
    "print('R^2 score for X_test:', model_knn.score(X_test, y_test))\n",
    "print('MSE:', mean_squared_error(y_test,y_pred_knn))\n",
    "print('RMSE:', mean_squared_error(y_test,y_pred_knn, squared=False))\n",
    "print('MAPE:',mape(y_test,y_pred_knn))\n",
    "print('RMSLE:',(mean_squared_log_error(y_test, y_pred_knn)**0.5),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking predictions\n",
    "plt.scatter(y_test,y_pred_knn)\n",
    "plt.title('Prediction Linearity')\n",
    "plt.show()\n",
    "\n",
    "# Checking residuals\n",
    "resid=y_test-y_pred_knn\n",
    "\n",
    "print(resid.mean())\n",
    "plt.plot(resid)\n",
    "plt.title('Residuals Variance')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(resid)\n",
    "plt.title('Distribution of residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model \n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(X_train, y_train)\n",
    "print(\"R^2 score for X_train:\", model_rf.score(X_train, y_train),'\\n')\n",
    "\n",
    "# predicting values \n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# checking evaluation metrics\n",
    "print('R^2 score for X_test:', model_rf.score(X_test, y_test))\n",
    "print('MSE:', mean_squared_error(y_test,y_pred_rf))\n",
    "print('RMSE:', mean_squared_error(y_test,y_pred_rf, squared=False))\n",
    "print('MAPE:',mape(y_test,y_pred_rf))\n",
    "print('RMSLE:',(mean_squared_log_error(y_test, y_pred_rf)**0.5),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred_rf)\n",
    "plt.title('Prediction Linearity')\n",
    "plt.show()\n",
    "\n",
    "# Checking residuals\n",
    "\n",
    "resid=y_test-y_pred_rf\n",
    "\n",
    "print(resid.mean())\n",
    "plt.plot(resid)\n",
    "plt.title('Residuals Variance')\n",
    "plt.show()\n",
    "\n",
    "sns.distplot(resid)\n",
    "plt.title('Distribution of residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "- At first sight the best model seems to be the Linear Regression because it has an higher R^2, it is not overfitted, the errors are the smallest (MAPE and MSE) and linearity of model seems better\n",
    "- In the meantime, the Linear Regression predicted 3 negative values which seems wrong\n",
    "- The models seems to be overfitted on the trained sample for KNN and Random Forest models \n",
    "- The RMSE score didn't increase much so we may consider that there are no outliers that affect the data\n",
    "\n",
    "**Possible improvements:**\n",
    "- Change parameters to see how it affects the models \n",
    "- Try other preprocessing methods (Sequential Selection, PCA and other scaling) to improve the resutls\n",
    "- Try Embedded feature engineering methods (Lasso)\n",
    "\n",
    "**Next Steps:**\n",
    "- Fix the negative value of Linear Prediction\n",
    "- Fix the overfitting of models\n",
    "- Check assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
