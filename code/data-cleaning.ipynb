{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Source of the dataset: http://insideairbnb.com/get-the-data.html\n",
    "\n",
    "I will be using the detailled dataset of listings because it has many interesting features. \n",
    "- Shape of listings csv is: (65493, 16)\n",
    "- Shape of listings_detailed csv is: (65493, 106)\n",
    "\n",
    "I will use the data scrapped last November (November 7, 2019) because the data won't depend on a crisis context.\n",
    "\n",
    "### Required actions:\n",
    "- drop duplicates and useless columns (with too many text description for example)\n",
    "- check and fix missing values\n",
    "- check data types and fix columns (43,61,62) that have mixed types\n",
    "- add new calculated columns to simplify the comprehension of data\n",
    "- transform f/t categorical columns to numerical 0/1\n",
    "- check other categorical columns and reduce or transform into numerical data if possible\n",
    "- transform dummies (need to think again about depending on the model I will use)\n",
    "\n",
    "\n",
    "categorical columns to be reduced: property_type, city, guests_included\n",
    "\n",
    "calculated columns: time_since_last_review, time_since_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "pd.set_option('max_columns',106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_full = pd.read_csv('http://data.insideairbnb.com/france/ile-de-france/paris/2019-11-07/data/listings.csv')\n",
    "print(listing_full.shape)\n",
    "listing_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "### Drop duplicates\n",
    "\n",
    "Checking duplicates and dropping them just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_full = listing_full.drop_duplicates()\n",
    "print(listing_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "### Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = listing_full.copy()\n",
    "col_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop.extend(listing_full.iloc[:,:21].columns)\n",
    "col_drop.extend(['host_name','host_about','host_thumbnail_url', 'host_has_profile_pic',\n",
    "                 'host_picture_url','host_neighbourhood','host_listings_count','host_verifications',\n",
    "                 'street','neighbourhood','neighbourhood_group_cleansed','state','zipcode','market',\n",
    "                 'smart_location','country_code','country','latitude','longitude','amenities',\n",
    "                 'calendar_updated','calendar_last_scraped','first_review','requires_license',\n",
    "                 'license','jurisdiction_names','has_availability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = list(set(col_drop))\n",
    "col_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the columns and their values 20 by 20\n",
    "\n",
    "df.iloc[:,80:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the different values for one column\n",
    "\n",
    "df[['calculated_host_listings_count','host_total_listings_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns\n",
    "\n",
    "df = df.drop(columns=col_drop)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________\n",
    "### Checking correlation to drop correlated columns and avoid multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "col_drop = []\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop.extend(['calculated_host_listings_count_entire_homes','availability_30',\n",
    "                 'availability_60','availability_90','minimum_minimum_nights','maximum_minimum_nights',\n",
    "                 'minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm',\n",
    "                 'maximum_nights_avg_ntm','calculated_host_listings_count','beds','number_of_reviews_ltm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns\n",
    "\n",
    "df1 = df1.drop(columns=col_drop)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking correlation between columns \n",
    "\n",
    "plt.figure(figsize=(17,10))\n",
    "sns.heatmap(df1.corr());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________\n",
    "### Checking and fixing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "col_drop = []\n",
    "row_drop = []\n",
    "\n",
    "null_col = df2.isna().sum()\n",
    "round(null_col[null_col>0]/df2.shape[0]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the review columns because it's not the most important feature for pricing and\n",
    "# there are too much missing values to handle\n",
    "\n",
    "# neighbourhood_cleansed seems to be really accurate so we can drop city which seems not so accurate\n",
    "\n",
    "col_drop.extend(['city','square_feet','weekly_price','monthly_price','host_location','host_acceptance_rate',\n",
    "                 'security_deposit','cleaning_fee','review_scores_rating','review_scores_accuracy',\n",
    "                 'review_scores_cleanliness','review_scores_checkin','review_scores_communication',\n",
    "                 'review_scores_location','review_scores_value','reviews_per_month','last_review'])\n",
    "\n",
    "row_drop.extend(df2[df2.host_since.isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns and rows\n",
    "\n",
    "df2 = df2.drop(columns=col_drop)\n",
    "df2 = df2.drop(index=row_drop)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.host_response_time = df2.host_response_time.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle nan values of host_response_rate. Nan values may mean the host has never received any message to answer.\n",
    "\n",
    "# Filling nan values and rid off % to convert values into integer and allow creation of bins\n",
    "df2.host_response_rate = df2.host_response_rate.fillna('-1').apply(lambda x: x.strip('%')).astype(int)\n",
    "\n",
    "# Creating bins for response rate\n",
    "df2.host_response_rate = pd.cut(df2.host_response_rate,[-2,-0.001,25,50,75,100], \n",
    "                                labels=['None','0-25%','25-50%','50-75%','75-100%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing vallues for bathrooms and bedrooms by 1.0\n",
    "# After checking the most frequent value is 1.0 for any accommodates (2,3,4,5) and any room_type\n",
    "\n",
    "print(\"bathrooms mode:\",df2[(df2.accommodates==2)&(df2.room_type=='Entire home/apt')].bathrooms.mode())\n",
    "df2.bathrooms = df2.bathrooms.fillna(1.0)\n",
    "\n",
    "print(\"bedrooms mode\",df2[(df2.accommodates==2)&(df2.room_type=='Entire home/apt')].bedrooms.mode())\n",
    "df2.bedrooms = df2.bedrooms.fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_col = df2.isna().sum()\n",
    "round(null_col[null_col>0]/df2.shape[0]*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "### Cleaning dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['price','extra_people']] = df3[['price','extra_people']].applymap(lambda x: x.strip('$').replace(',','')).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.host_since = pd.to_datetime(df3.host_since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________\n",
    "### Creating new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.today()\n",
    "df3['time_since_host'] = (current_date - df3.host_since).dt.days\n",
    "df3 = df3.drop('host_since',axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________\n",
    "### Transform categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the list of property_type by keeping top 10 and put other categories into Other\n",
    "\n",
    "top_10_prop = df4.property_type.value_counts().head(10).index\n",
    "df4.property_type = df4.property_type.apply(lambda x: x if x in top_10_prop else 'Other')\n",
    "df4.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming boolean values into integer\n",
    "\n",
    "df4[['host_is_superhost','host_identity_verified',\n",
    "     'is_location_exact','instant_bookable',\n",
    "     'is_business_travel_ready','require_guest_profile_picture',\n",
    "     'require_guest_phone_verification']] = df4[['host_is_superhost','host_identity_verified',\n",
    "     'is_location_exact','instant_bookable',\n",
    "     'is_business_travel_ready','require_guest_profile_picture',\n",
    "     'require_guest_phone_verification']].applymap(lambda x: 1 if x=='t' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the csv without dummies for EDA\n",
    "\n",
    "df4.to_csv('../data/airbnb_paris_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "df5 = pd.get_dummies(df5,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the csv with dummies\n",
    "\n",
    "df5.to_csv('../data/airbnb_paris_clean_dummies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
