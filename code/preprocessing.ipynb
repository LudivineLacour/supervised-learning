{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "- Scaling between 0 and 1 because we have a lot of dummies and columns with boolean values\n",
    "- Feature engineering using filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "pd.set_option('max_columns',70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/airbnb_paris_clean_dummies.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking duplicates and drop them\n",
    "\n",
    "print(\"duplicates found:\",df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________\n",
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scale = df[['time_since_host','number_of_reviews','availability_365','extra_people','guests_included','price',\n",
    "'bedrooms','bathrooms','accommodates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking distribution and value range before scaling \n",
    "\n",
    "fig,axs=plt.subplots(2,5,figsize=(17,8))\n",
    "\n",
    "for i in range(to_scale.shape[1]):\n",
    "    ax = axs[i//5,i%5]\n",
    "    sns.distplot(to_scale.iloc[:,i],ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating  copy of initial dataframe in case of mistake\n",
    "\n",
    "df_scaled = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data using MinMax method to put all data between 0,1 because we have many columns with dummies\n",
    "# Also MixMax Scale is recommanded for algos distance-based such as KNN or XGboost\n",
    "\n",
    "for i in range(to_scale.columns.shape[0]):\n",
    "    df_scaled[to_scale.columns[i]] = (df_scaled[to_scale.columns[i]] - df_scaled[to_scale.columns[i]].min())/(df_scaled[to_scale.columns[i]].max()-df_scaled[to_scale.columns[i]].min())\n",
    "\n",
    "df_scaled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________\n",
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering using Filter method with f-regression for Linear Regression model \n",
    "# and mutual_info_regression for KNN and XGboost models\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "\n",
    "X = df.drop('price',axis=1)\n",
    "y = df.price\n",
    "\n",
    "X_scaled = df_scaled.drop('price',axis=1)\n",
    "y_scaled = df_scaled.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_freg = SelectKBest(f_regression)\n",
    "X_new_freg = selection_freg.fit_transform(X_scaled,y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_freg = pd.DataFrame(X_new_freg)\n",
    "print(X_new_freg.shape)\n",
    "X_new_freg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_mireg = SelectKBest(mutual_info_regression)\n",
    "X_new_mireg = selection_mireg.fit_transform(X_scaled,y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_mireg = pd.DataFrame(X_new_mireg)\n",
    "print(X_new_mireg.shape)\n",
    "X_new_mireg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true,y_pred):\n",
    "    if y_true.any() == 0:\n",
    "        return \"dividing by 0 is impossible\"\n",
    "    else:\n",
    "        return np.mean(np.abs((y_true-y_pred)/y_pred))*100\n",
    "    \n",
    "mape(y_scaled,y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using RFE method\n",
    "\n",
    "# build RFE on non-scaled df\n",
    "estimator = LinearRegression()\n",
    "selection = RFE(estimator, 10)\n",
    "selection.fit(X,y)\n",
    "print(X.columns[selection.support_])\n",
    "y_pred_rfe = selection.predict(X)\n",
    "print('R2 using RFE method:',r2_score(y,y_pred_rfe))\n",
    "print('MAPE:',mape(y,y_pred_rfe),'\\n')\n",
    "\n",
    "# build RFE using scaled df\n",
    "estimator2 = LinearRegression()\n",
    "selection2 = RFE(estimator2, 10)\n",
    "selection2.fit(X_scaled,y_scaled)\n",
    "print(X_scaled.columns[selection2.support_])\n",
    "y_pred_rfe2 = selection2.predict(X_scaled)\n",
    "print('R2 using RFE method:',r2_score(y_scaled,y_pred_rfe2))\n",
    "print('MAPE:',mape(y_scaled,y_pred_rfe2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_RFE = X_scaled[X_scaled.columns[selection2.support_]]\n",
    "X_new_RFE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the performance of model depending on columns used (w/ and w/o filter method)\n",
    "\n",
    "# Use df scaled without any feature engineering method (so all columns)\n",
    "lin_model2 = LinearRegression()\n",
    "lin_model_fitted2 = lin_model2.fit(X_scaled,y_scaled)\n",
    "y_pred_lin2 = lin_model_fitted2.predict(X_scaled)\n",
    "print('R2 w/o feature engineering methods',r2_score(y_scaled,y_pred_lin2))\n",
    "print('MAPE:',mape(y_scaled,y_pred_lin2),'\\n')\n",
    "\n",
    "# Use df non-scaled without any feature engineering method (so all columns)\n",
    "lin_model3 = LinearRegression()\n",
    "lin_model_fitted3 = lin_model3.fit(X,y)\n",
    "y_pred_lin3 = lin_model_fitted3.predict(X)\n",
    "print('R2 w/o feature engineering methods nor scaling',r2_score(y,y_pred_lin3))\n",
    "print('MAPE:',mape(y,y_pred_lin3),'\\n')\n",
    "\n",
    "# Use filter method\n",
    "lin_model = LinearRegression()\n",
    "lin_model_fitted = lin_model.fit(X_new_freg,y_scaled)\n",
    "y_pred_lin = lin_model_fitted.predict(X_new_freg)\n",
    "print('R2 using filter method:',r2_score(y_scaled,y_pred_lin))\n",
    "print('MAPE:',mape(y_scaled,y_pred_lin),'\\n')\n",
    "\n",
    "# Use RFE method\n",
    "lin_model4 = LinearRegression()\n",
    "lin_model_fitted4 = lin_model4.fit(X_new_RFE,y_scaled)\n",
    "y_pred_lin4 = lin_model_fitted4.predict(X_new_RFE)\n",
    "print('R2 using RFE method:',r2_score(y_scaled,y_pred_lin4))\n",
    "print('MAPE:',mape(y_scaled,y_pred_lin4),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "- using scaling is better for linear regression especially if using RFE method for feature engineering\n",
    "- filter method seems to have better performance than RFE (R2 is better) but errors are the same\n",
    "- In any case it is better to use feature engineering methods because errors are smaller\n",
    "\n",
    "**Possible improvements:**\n",
    "- test Sequential Selection to find out the best number of features needed and compare results with other methods\n",
    "- test with different number of features\n",
    "- run PCA\n",
    "\n",
    "**Next steps:**\n",
    "- export new csv with scaled data and RFE method \n",
    "- run LinearRegression, KNN and RandomForest models to compare results using evaluation metrics for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the new csv with feature engineering methods\n",
    "\n",
    "feat_df = df_scaled[list(df_scaled.drop('price',axis=1).columns[selection2.support_])+['price']]\n",
    "print(feat_df.shape)\n",
    "\n",
    "feat_df.to_csv('../data/airbnb_paris_clean_feat.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
